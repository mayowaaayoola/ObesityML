{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 95.6400\n",
      "Epoch 2/20, Loss: 67.0345\n",
      "Epoch 3/20, Loss: 46.5499\n",
      "Epoch 4/20, Loss: 36.0398\n",
      "Epoch 5/20, Loss: 28.1605\n",
      "Epoch 6/20, Loss: 22.7283\n",
      "Epoch 7/20, Loss: 19.1937\n",
      "Epoch 8/20, Loss: 16.2071\n",
      "Epoch 9/20, Loss: 13.9482\n",
      "Epoch 10/20, Loss: 12.0684\n",
      "Epoch 11/20, Loss: 10.7799\n",
      "Epoch 12/20, Loss: 9.5159\n",
      "Epoch 13/20, Loss: 8.7886\n",
      "Epoch 14/20, Loss: 8.0113\n",
      "Epoch 15/20, Loss: 7.5101\n",
      "Epoch 16/20, Loss: 6.5919\n",
      "Epoch 17/20, Loss: 6.2937\n",
      "Epoch 18/20, Loss: 6.0901\n",
      "Epoch 19/20, Loss: 5.7193\n",
      "Epoch 20/20, Loss: 5.3810\n",
      "Accuracy: 0.9385342789598109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        54\n",
      "           1       0.92      0.76      0.83        58\n",
      "           2       0.96      1.00      0.98        70\n",
      "           3       1.00      0.98      0.99        60\n",
      "           4       1.00      1.00      1.00        65\n",
      "           5       0.82      0.91      0.86        58\n",
      "           6       0.98      0.90      0.94        58\n",
      "\n",
      "    accuracy                           0.94       423\n",
      "   macro avg       0.94      0.94      0.94       423\n",
      "weighted avg       0.94      0.94      0.94       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\user\\Desktop\\OBS_Pred\\ObesityDataSet_raw_and_data_sinthetic.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Encode categorical features\n",
    "label_cols = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for col in label_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "# Normalize numerical columns\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop(columns=['NObeyesdad']).values\n",
    "y = df['NObeyesdad'].values\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_test = torch.tensor(X_train, dtype=torch.float32), torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train, y_test = torch.tensor(y_train, dtype=torch.long), torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "class ObesityNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ObesityNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Model setup\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = len(np.unique(y))  # Number of unique obesity classes\n",
    "\n",
    "model = ObesityNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111 entries, 0 to 2110\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          2111 non-null   object \n",
      " 1   Age                             2111 non-null   int64  \n",
      " 2   Height                          2111 non-null   float64\n",
      " 3   Weight                          2111 non-null   float64\n",
      " 4   family_history_with_overweight  2111 non-null   object \n",
      " 5   FAVC                            2111 non-null   object \n",
      " 6   FCVC                            2111 non-null   float64\n",
      " 7   NCP                             2111 non-null   float64\n",
      " 8   CAEC                            2111 non-null   object \n",
      " 9   SMOKE                           2111 non-null   object \n",
      " 10  CH2O                            2111 non-null   float64\n",
      " 11  SCC                             2111 non-null   object \n",
      " 12  FAF                             2111 non-null   float64\n",
      " 13  TUE                             2111 non-null   float64\n",
      " 14  CALC                            2111 non-null   object \n",
      " 15  MTRANS                          2111 non-null   object \n",
      " 16  NObeyesdad                      2111 non-null   object \n",
      "dtypes: float64(7), int64(1), object(9)\n",
      "memory usage: 280.5+ KB\n",
      "None\n",
      "   Gender  Age  Height  Weight family_history_with_overweight FAVC  FCVC  NCP  \\\n",
      "0  Female   21    1.62    64.0                            yes   no   2.0  3.0   \n",
      "1  Female   21    1.52    56.0                            yes   no   3.0  3.0   \n",
      "2    Male   23    1.80    77.0                            yes   no   2.0  3.0   \n",
      "3    Male   27    1.80    87.0                             no   no   3.0  3.0   \n",
      "4    Male   22    1.78    89.8                             no   no   2.0  1.0   \n",
      "\n",
      "        CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC                 MTRANS  \\\n",
      "0  Sometimes    no   2.0   no  0.0  1.0          no  Public_Transportation   \n",
      "1  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes  Public_Transportation   \n",
      "2  Sometimes    no   2.0   no  2.0  1.0  Frequently  Public_Transportation   \n",
      "3  Sometimes    no   2.0   no  2.0  0.0  Frequently                Walking   \n",
      "4  Sometimes    no   2.0   no  0.0  0.0   Sometimes  Public_Transportation   \n",
      "\n",
      "            NObeyesdad  \n",
      "0        Normal_Weight  \n",
      "1        Normal_Weight  \n",
      "2        Normal_Weight  \n",
      "3   Overweight_Level_I  \n",
      "4  Overweight_Level_II  \n",
      "   Gender       Age    Height    Weight  family_history_with_overweight  FAVC  \\\n",
      "0       0 -0.521741 -0.874380 -0.862558                               1     0   \n",
      "1       0 -0.521741 -1.945660 -1.168077                               1     0   \n",
      "2       1 -0.207057  1.053924 -0.366089                               1     0   \n",
      "3       1  0.422312  1.053924  0.015809                               0     0   \n",
      "4       1 -0.364399  0.839668  0.122741                               0     0   \n",
      "\n",
      "       FCVC       NCP  CAEC  SMOKE      CH2O  SCC       FAF       TUE  CALC  \\\n",
      "0 -0.784810  0.404102     2      0 -0.013141    0 -1.188028  0.562005     3   \n",
      "1  1.088307  0.404102     2      1  1.618701    1  2.339676 -1.080619     2   \n",
      "2 -0.784810  0.404102     2      0 -0.013141    0  1.163774  0.562005     1   \n",
      "3  1.088307  0.404102     2      0 -0.013141    0  1.163774 -1.080619     1   \n",
      "4 -0.784810 -2.166941     2      0 -0.013141    0 -1.188028 -1.080619     2   \n",
      "\n",
      "   MTRANS  NObeyesdad  \n",
      "0       3           1  \n",
      "1       3           1  \n",
      "2       3           1  \n",
      "3       4           5  \n",
      "4       3           6  \n",
      "Accuracy: 0.9527186761229315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        54\n",
      "           1       0.83      0.98      0.90        58\n",
      "           2       0.96      0.97      0.96        70\n",
      "           3       1.00      0.98      0.99        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.94      0.88      0.91        58\n",
      "           6       0.96      0.93      0.95        58\n",
      "\n",
      "    accuracy                           0.95       423\n",
      "   macro avg       0.96      0.95      0.95       423\n",
      "weighted avg       0.96      0.95      0.95       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\user\\Desktop\\OBS_Pred\\ObesityDataSet_raw_and_data_sinthetic.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "# Encoding categorical features\n",
    "label_cols = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for col in label_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "# Normalize numerical columns\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "X = df.drop(columns=['NObeyesdad'])  # Features\n",
    "y = df['NObeyesdad']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train a Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Accuracy: 0.8723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        54\n",
      "           1       0.82      0.69      0.75        58\n",
      "           2       0.89      0.94      0.92        70\n",
      "           3       0.95      0.98      0.97        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.71      0.78      0.74        58\n",
      "           6       0.81      0.74      0.77        58\n",
      "\n",
      "    accuracy                           0.87       423\n",
      "   macro avg       0.87      0.87      0.87       423\n",
      "weighted avg       0.87      0.87      0.87       423\n",
      "\n",
      "\n",
      "Training Support Vector Machine...\n",
      "Accuracy: 0.9480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        54\n",
      "           1       0.96      0.83      0.89        58\n",
      "           2       0.99      0.96      0.97        70\n",
      "           3       0.97      1.00      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.86      0.95      0.90        58\n",
      "           6       0.95      0.91      0.93        58\n",
      "\n",
      "    accuracy                           0.95       423\n",
      "   macro avg       0.95      0.95      0.95       423\n",
      "weighted avg       0.95      0.95      0.95       423\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Accuracy: 0.9527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        54\n",
      "           1       0.83      0.98      0.90        58\n",
      "           2       0.96      0.97      0.96        70\n",
      "           3       1.00      0.98      0.99        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.94      0.88      0.91        58\n",
      "           6       0.96      0.93      0.95        58\n",
      "\n",
      "    accuracy                           0.95       423\n",
      "   macro avg       0.96      0.95      0.95       423\n",
      "weighted avg       0.96      0.95      0.95       423\n",
      "\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:34:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93        54\n",
      "           1       0.85      0.95      0.89        58\n",
      "           2       0.97      0.97      0.97        70\n",
      "           3       0.98      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.98      0.91      0.95        58\n",
      "           6       0.97      0.98      0.97        58\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.96      0.96      0.96       423\n",
      "weighted avg       0.96      0.96      0.96       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\user\\Desktop\\OBS_Pred\\ObesityDataSet_raw_and_data_sinthetic.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Encoding categorical features\n",
    "label_cols = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']\n",
    "encoder = LabelEncoder()\n",
    "for col in label_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "# Normalize numerical columns\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# Splitting data into features (X) and target (y)\n",
    "X = df.drop(columns=['NObeyesdad'])\n",
    "y = df['NObeyesdad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
